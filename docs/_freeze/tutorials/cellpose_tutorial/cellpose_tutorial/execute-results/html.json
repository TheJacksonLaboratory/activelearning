{
  "hash": "fe1b377b383ba8a94caf2bbe49119009",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Tutorial: How to fine tune a Cellpose model with the Active Learning plugin for Napari\"\nauthor: Fernando Cervantes\ncategories: [Cellpose, Transfer learning] # self-defined categories\n\ndescription: Tutorial for fine-tuning the \"nuclei\" model from `cellpose` to new data.\n\nformat:\n  revealjs:\n    output-file: cellpose_tutorial_presentation\n    code-fold: false\n    progress: true\n    controls: true\n    fontsize: 18pt\n\n  html:\n    toc: true\n\nexecute: \n  cache: true\n\njupyter: python3\n---\n\n\n# 0. Install `napari` and the Active Learning plugin\n\n---\n\n### 0.1. Install `napari`\n\nFollow the instructions to install `napari` from its [official website](https://napari.org/stable/tutorials/fundamentals/installation.html#napari-installation).\n\n### 0.2. Install the `napari-activelearning` plugin using `pip`\n\n::: {.callout-important}\nIf you installed `napari` using conda, activate that same environment before installing the _Active Learning_ plugin.\n:::\n\nInstall the plugin adding `[cellpose]` to the command so all dependencies required for this tutorial are available.\n\n```\npython -m pip install \"napari-activelearning[cellpose]\"\n```\n\n\n# 1. Image groups management\n\n## 1.1. Load a sample image\n\nYou can use the cells 3D image sample from napari's built-in samples.\n\n```\nFile > Open Sample > napari builtins > Cells (3D+2Ch)\n```\n\n\n\n\n\n\n\n::: {#4a46f17d .cell execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=4}\n![](cellpose_tutorial_files/figure-revealjs/cell-5-output-1.png){}\n:::\n:::\n\n\n## 1.2. Add the _Image Groups Manager_ widget to napari's window\n\nThe _Image groups manager_ can be found under the _Active Learning_ plugin in napari's plugins menu.\n\n```\nPlugins > Active Learning > Image groups manager\n```\n\n\n\n\n\n::: {#8e7fba83 .cell execution_count=7}\n\n::: {.cell-output .cell-output-display execution_count=7}\n![](cellpose_tutorial_files/figure-revealjs/cell-8-output-1.png){}\n:::\n:::\n\n\n## 1.3. Create an _Image Group_ containing _nuclei_ and _membrane_ layers\n\n1. Select the _nuclei_ and _membrane_ layer\n\n2. Click the _New Image Group_ button on the _Image Groups Manager_ widget\n\n\n\n::: {#01f1e215 .cell execution_count=9}\n\n::: {.cell-output .cell-output-display execution_count=9}\n![](cellpose_tutorial_files/figure-revealjs/cell-10-output-1.png){}\n:::\n:::\n\n\n\n\n## 1.4. Edit the image group properties\n\n:::: {.columns}\n\n::: {.column width=0.3}\n1. Select the newly created image group, it will appear as \"images\" in the _Image groups manager_ widget.\n\n2. Click the _Edit group properties_ checkbox.\n\n3. Make sure that _Axes order_ is \"CZYX\", otherwise, you can edit it and press _Enter_ to update the axes names.\n:::\n\n::: {.column width=0.7}\n\n\n\n::: {#a29be26a .cell execution_count=12}\n\n::: {.cell-output .cell-output-display execution_count=12}\n![](cellpose_tutorial_files/figure-revealjs/cell-13-output-1.png){}\n:::\n:::\n\n\n:::\n\n::::\n\n# 2. Segmentation on image groups\n\n## 2.1. Add the _Acquisition function configuration_ widget to napari's window\n\nThe _Acquisition function configuration_ is under the _Active Learning_ plugin in napari's plugins menu.\n\n```\nPlugins > Active Learning > Acquisition function configuration\n```\n\n::: {.callout-tip}\nAll _Active Learning_ widgets can be _un-docked_ from their current place and _re-docked_ into other more convenient location within napari's window, or even as tabs, as illustrated in this tutorial.\n:::\n\n\n\n\n\n::: {#2710d37c .cell execution_count=15}\n\n::: {.cell-output .cell-output-display execution_count=15}\n![](cellpose_tutorial_files/figure-revealjs/cell-16-output-1.png){}\n:::\n:::\n\n\n## 2.2. Define sampling configuration\n\n:::: {.columns}\n\n::: {.column width=0.3}\n\n1. Make sure \"Input axes\" are set to \"ZYX\"\n\n::: {.callout-note}\nThis specifies that the samples will be taken from those axes.\n:::\n\n2. Change the \"Model axes\" to \"CYX\"\n\n::: {.callout-note}\nAnd this specifies that sample's axes will be permuted to match the \"Model axes\" order.\n:::\n\n:::\n\n::: {.column width=0.3}\n\n\n\n::: {#05133435 .cell execution_count=17}\n\n::: {.cell-output .cell-output-display execution_count=17}\n![](cellpose_tutorial_files/figure-revealjs/cell-18-output-1.png){}\n:::\n:::\n\n\n:::\n\n::::\n\n## 2.3. Set the size of the sampling patch\n\n:::: {.columns}\n\n::: {.column width=0.70}\n\n\n\n::: {#d41c35ca .cell execution_count=19}\n\n::: {.cell-output .cell-output-display execution_count=19}\n![](cellpose_tutorial_files/figure-revealjs/cell-20-output-1.png){}\n:::\n:::\n\n\n:::\n\n::: {.column width=0.30}\n\n1. Click the \"Edit patch size\" checkbox\n2. Change the patch size of \"X\" and \"Y\" to 256, and the \"Z\" axis to 1.\n\n:::{.callout-note}\nThis directs the Active Learning plugin to sample at random patches of size $256\\times256$ pixels, and $1$ slice of depth.\n:::\n\n:::\n\n::::\n\n## 2.4. Define the maximum number of samples to extract\n\n:::: {.columns}\n\n::: {.column width=0.4}\n\n\n\n::: {#276bee03 .cell execution_count=21}\n\n::: {.cell-output .cell-output-display execution_count=21}\n![](cellpose_tutorial_files/figure-revealjs/cell-22-output-1.png){}\n:::\n:::\n\n\n:::\n\n::: {.column width=0.6}\n- Set the \"Maximum samples\" to $4$ and press _Enter_\n\n:::{.callout-note}\nThis tells the Active Learning plugin to process at most _four_ samples at random from the whole image.\n:::\n\n:::\n\n::::\n\n\n## 2.5. Configure the segmentation method\n\n:::: {.columns}\n\n::: {.column width=0.6}\n\n1. Use the \"Model\" dropdown list to select the `cellpose` method\n\n2. Click the \"Advanced segmentation parameters\" checkbox\n\n3. Change the \"Channel axis\" to $0$\n\n::: {.callout-note}\nThis makes `cellpose` to use the first axis as \"Color\" channel.\n:::\n\n4. Change the second channel to $1$ (the right spin box in the \"channels\" row)\n\n::: {.callout-note}\nThis tells `cellpose` to segment the first channel ($0$) and use the second channel ($1$) as help channel.\n:::\n\n5. Choose the \"nuclei\" model from the dropdown list\n\n\n:::\n\n::: {.column width=0.4}\n\n\n\n::: {#359687c0 .cell execution_count=23}\n\n::: {.cell-output .cell-output-display execution_count=23}\n![](cellpose_tutorial_files/figure-revealjs/cell-24-output-1.png){}\n:::\n:::\n\n\n:::\n\n::::\n\n## 2.6. Execute the segmentation method on all image groups\n\n:::: {.columns}\n\n::: {.column width=0.6}\n- Click the \"Run on all image groups\" button\n\n::: {.callout-note}\nTo execute the segmentation only on specific image groups, select the desired image groups in the _Image groups manager_ widget and use the \"Run on selected image groups\" button instead.\n:::\n\n:::\n\n::: {.column width=0.4}\n\n::: {#b71c2918 .cell execution_count=24}\n\n::: {.cell-output .cell-output-display execution_count=24}\n![](cellpose_tutorial_files/figure-revealjs/cell-25-output-1.png){}\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n## 2.7. Inspect the segmentation layer\n\n::: {.callout-note}\nBecause the input image is 3D, you might have to slide the Z index at the bottom of napari's window to look at the samples that have been segmented.\n:::\n\n\n\n::: {#adb69dbc .cell execution_count=27}\n\n::: {.cell-output .cell-output-display execution_count=27}\n![](cellpose_tutorial_files/figure-revealjs/cell-28-output-1.png){}\n:::\n:::\n\n\n# 3. Segment masked regions only\n\n## 3.1. Create a mask to restrict the sampling space\n\n:::: {.columns}\n\n::: {.column width=0.6}\n1. Switch to the _Image groups manager_ tab\n\n2. Click the \"Edit mask properties\" checkbox\n\n3. Set the mask scale to $256$ for the \"X\" and \"Y\" axes, and a scale of $1$ for the \"Z\" axis\n\n4. Click the \"Create mask\" button\n\n::: {.callout-note}\nThis creates a low-resolution mask where each of its pixels corresponds to a $256\\times256$ pixels region in the input image.\nBecause the mask is low-resolution, it uses less space in memory and disk.\n:::\n\n:::\n\n::: {.column width=0.4}\n\n\n\n::: {#835f940d .cell execution_count=29}\n\n::: {.cell-output .cell-output-display execution_count=29}\n![](cellpose_tutorial_files/figure-revealjs/cell-30-output-1.png){}\n:::\n:::\n\n\n:::\n\n::::\n\n\n## 3.2. Specify the samplable regions\n\n- Draw a mask that covers slices $27$ to $30$ in the \"Z\" axis.\n\n::: {.callout-note}\nMove the slider at the bottom of napari's window to navigate between slices in the \"Z\" axis.\n:::\n\n\n\n::: {#8560f557 .cell execution_count=31}\n\n::: {.cell-output .cell-output-display execution_count=31}\n![](cellpose_tutorial_files/figure-revealjs/cell-32-output-1.png){}\n:::\n:::\n\n\n## 3.3. Execute the segmentation process on the masked regions\n\n:::: {.columns}\n\n::: {.column width=0.6}\n\n1. Go back to the _Acquisition function configuration_ widget\n\n2. Click the \"Run on all image groups\" button again\n\n::: {.callout-note}\nBecause the image group has a defined mask, samples will be extracted at random inside those defined regions only.\n:::\n\n:::\n\n::: {.column width=0.4}\n\n\n\n::: {#772b4192 .cell execution_count=33}\n\n::: {.cell-output .cell-output-display execution_count=33}\n![](cellpose_tutorial_files/figure-revealjs/cell-34-output-1.png){}\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n## 3.4. Inspect the masked segmentation output\n\n::: {#28242bfa .cell execution_count=35}\n\n::: {.cell-output .cell-output-display execution_count=35}\n![](cellpose_tutorial_files/figure-revealjs/cell-36-output-1.png){}\n:::\n:::\n\n\n# 4. Fine tune the segmentation model\n\n## 4.1. Add the _Label groups manager_ widget to napari's window\n\nYou can find the _Label groups manager_ under the _Active Learning_ plugin in napari's plugins menu.\n\n```\nPlugins > Active Learning > Label groups manager\n```\n\n\n\n\n\n::: {#b7dc39f2 .cell execution_count=38}\n\n::: {.cell-output .cell-output-display execution_count=38}\n![](cellpose_tutorial_files/figure-revealjs/cell-39-output-1.png){}\n:::\n:::\n\n\n## 4.2. Select a segmented patch to edit\n\n- Double click on any segmented patch in the viewer \n(e.g. on slice $27$)\n\n::: {.callout-note}\nThis creates a new editable \"Labels edit\" layer with a copy of the selected patch.\n:::\n\n\n\n::: {#449dc337 .cell execution_count=40}\n\n::: {.cell-output .cell-output-display execution_count=40}\n![](cellpose_tutorial_files/figure-revealjs/cell-41-output-1.png){}\n:::\n:::\n\n\n## 4.3. Use napari's layer controls to make changes on the objects of the current patch\n\n::: {#a7a1d455 .cell execution_count=41}\n\n::: {.cell-output .cell-output-display execution_count=41}\n![](cellpose_tutorial_files/figure-revealjs/cell-42-output-1.png){}\n:::\n:::\n\n\n## 4.4. Commit changes to the labels layer\n\n- Once you have finished editing the labels, click the \"Commit changes\" button on the _Label groups manager_\n\n\n\n::: {#93c75699 .cell execution_count=43}\n\n::: {.cell-output .cell-output-display execution_count=43}\n![](cellpose_tutorial_files/figure-revealjs/cell-44-output-1.png){}\n:::\n:::\n\n\n\n\n## 4.5. Navigate between segmented patches\n\n:::: {.columns}\n\n::: {.column width=0.6}\n1. Expand the second group of labels\n\n2. Double-click on any of the nested items to open it for editing\n\n3. Use the navigation buttons to move between segmented patches\n\n4. Continue editing the segmentation in the current patch and commit the changes when finished\n:::\n\n::: {.column width=0.4}\n\n\n\n::: {#67189b1b .cell execution_count=46}\n\n::: {.cell-output .cell-output-display execution_count=46}\n![](cellpose_tutorial_files/figure-revealjs/cell-47-output-1.png){}\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n## 4.6. Setup fine tuning configuration\n\n:::: {.columns}\n\n::: {.column width=0.6}\n\n1. Go to the _Acquisition function configuration_ widget\n\n2. Click the \"Advanced fine tuning parameters\" checkbox\n\n3. Change the \"save path\" to a location where you want to store the fine tuned model\n\n:::\n\n::: {.column width=0.4}\n\n\n\n\n\n::: {#df374edb .cell execution_count=50}\n\n::: {.cell-output .cell-output-display execution_count=50}\n![](cellpose_tutorial_files/figure-revealjs/cell-51-output-1.png){}\n:::\n:::\n\n\n:::\n\n::::\n\n## 4.6. Setup fine tuning configuration\n\n:::: {.columns}\n\n::: {.column width=0.6}\n\n4. Change the \"model name\" to \"nuclei_ft\"\n\n::: {.callout-note}\nScroll the _Advanced fine tuning parameters_ widget down to show more parameters.\n:::\n\n5. Set the \"batch size\" to $3$\n\n6. Change the \"learning rate\" to $0.0001$\n\n::: {.callout-note}\nYou can modify other parameters for the training process here, such as the number of training epochs.\n:::\n\n:::\n\n::: {.column width=0.4}\n\n\n\n::: {#7c537e22 .cell execution_count=52}\n\n::: {.cell-output .cell-output-display execution_count=52}\n![](cellpose_tutorial_files/figure-revealjs/cell-53-output-1.png){}\n:::\n:::\n\n\n:::\n\n::::\n\n## 4.7. Execute the fine tuning process\n\n:::: {.columns}\n\n::: {.column width=0.6}\n- Click the \"Fine tune model\" button to run the training process.\n\n::: {.callout-note}\nDepending on your computer resources (RAM, CPU), this process might take some minutes to complete. If you have a dedicated GPU device, this can take a couple of seconds instead.\n:::\n\n:::\n\n::: {.column width=0.4}\n\n::: {#e2d1db61 .cell execution_count=53}\n\n::: {.cell-output .cell-output-display execution_count=53}\n![](cellpose_tutorial_files/figure-revealjs/cell-54-output-1.png){}\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n## 4.8. Review the fine tuned segmentation\n\n::: {.callout-tip}\nUse the *opacity* slider to compare how the fine tuned model segments the same objects that were labeled for training.\n:::\n\n::: {#b7bace73 .cell execution_count=55}\n\n::: {.cell-output .cell-output-display execution_count=55}\n![](cellpose_tutorial_files/figure-revealjs/cell-56-output-1.png){}\n:::\n:::\n\n\n# 5. Use the fine tuned model for inference\n\n## 5.1. Create a mask to apply the fine tuned model for inference\n\n:::: {.columns}\n\n::: {.column width=0.6}\n\n1. Switch to the _Image groups manager_ tab\n\n2. Click the \"Edit mask properties\" checkbox\n\n3. Set the mask scale to $256$ for the \"X\" and \"Y\" axes, and a scale of $1$ for the \"Z\" axis\n\n4. Click the \"Create mask\" button\n\n:::\n\n::: {.column width=0.4}\n\n\n\n::: {#4eab61ff .cell execution_count=57}\n\n::: {.cell-output .cell-output-display execution_count=57}\n![](cellpose_tutorial_files/figure-revealjs/cell-58-output-1.png){}\n:::\n:::\n\n\n:::\n\n::::\n\n## 5.2. Specify the samplable regions for inference\n\n- Draw a mask that covers slices $31$ to $34$ in the \"Z\" axis.\n\n\n\n::: {#b7b3e53a .cell execution_count=59}\n\n::: {.cell-output .cell-output-display execution_count=59}\n![](cellpose_tutorial_files/figure-revealjs/cell-60-output-1.png){}\n:::\n:::\n\n\n## 5.3. Select the new mask layer to be used for sampling positions\n\n:::: {.columns}\n\n::: {.column width=0.6}\n\n1. Scroll down the _Image groups manager_ tree to show the newest mask layer grup (\"mask (1)\")\n\n2. Select the \"mask (1)\" layer group\n\n::: {.callout-note}\nThe \"Group name\" column in the groups tree can be resized to show the complete names.\n:::\n\n3. Make sure that \"Use as sampling mask\" checkbox is checked\n\n:::\n\n::: {.column width=0.4}\n\n\n\n::: {#ed799d93 .cell execution_count=61}\n\n::: {.cell-output .cell-output-display execution_count=61}\n![](cellpose_tutorial_files/figure-revealjs/cell-62-output-1.png){}\n:::\n:::\n\n\n:::\n\n::::\n\n\n## 5.4. Use the fine tuned model for inference in the masked region\n\n:::: {.columns}\n\n::: {.column width=0.6}\n\n1. Go back to the _Acquisition function configuration_ widget\n\n2. Click \"Run on all image groups\" button again\n\n:::\n\n::: {.column width=0.4}\n\n\n\n::: {#0ef68975 .cell execution_count=63}\n\n::: {.cell-output .cell-output-display execution_count=63}\n![](cellpose_tutorial_files/figure-revealjs/cell-64-output-1.png){}\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n## 5.5. Inspect the output of the fine tuned model\n\n- Now you have a fine tuned model for nuclei segmentation that has been adapted to this image!\n\n::: {.callout-note}\nThe fine tuned model can be used in *Cellpose*'s GUI software, their python API package, or any other package that supports pretrained `cellpose` models.\n:::\n\n\n\n::: {#0b98b4f6 .cell execution_count=66}\n\n::: {.cell-output .cell-output-display execution_count=66}\n![](cellpose_tutorial_files/figure-revealjs/cell-67-output-1.png){}\n:::\n:::\n\n\n## 5.6. Segment the newly masked region with the base model\n\n:::: {.columns}\n\n::: {.column width=0.6}\n\n1. Choose the \"nuclei\" model again from the dropdown list in the _Advanced segmentation parameters_ section\n\n2. Click the \"Run on all image groups\" button again\n\n::: {.callout-note}\nThis will execute the segmentation process with the non-fine-tuned \"nuclei\" model on the same sampling positions from the last run.\n:::\n\n:::\n\n::: {.column width=0.4}\n\n\n\n::: {#780497a8 .cell execution_count=68}\n\n::: {.cell-output .cell-output-display execution_count=68}\n![](cellpose_tutorial_files/figure-revealjs/cell-69-output-1.png){}\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n## 5.7. Compare the results of both models\n\n::: {.callout-tip}\nHide all the layers and show only the \"nuclei\" and \"membrane\" layers, as well as the \"images segmentation [2]\" and \"images segmentation [3]\" layers that correspond to the output of the fine tuned model and base model, respectively.\n:::\n\n\n\n::: {#c2ea7cf8 .cell execution_count=71}\n\n::: {.cell-output .cell-output-display execution_count=71}\n![](cellpose_tutorial_files/figure-revealjs/cell-72-output-1.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "cellpose_tutorial_files"
    ],
    "filters": [],
    "includes": {}
  }
}