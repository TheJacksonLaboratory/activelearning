---
title: "Tutorial: How to fine tune a Cellpose model with the Active Learning plugin for Napari"
author: Fernando Cervantes
categories: [Cellpose, Transfer learning] # self-defined categories

description: Tutorial for fine-tuning the "nuclei" model from `cellpose` to new data.

format:
  revealjs:
    output-file: cellpose_tutorial_presentation
    code-fold: false
    progress: true
    controls: true
    fontsize: 18pt

  html:
    toc: true

execute: 
  cache: true

jupyter: python3
---

# 1. Install `napari` and the Active Learning plugin

---

### 1.1. Install `napari`

Follow the instructions to install `napari` from its [official website](https://napari.org/stable/tutorials/fundamentals/installation.html#napari-installation).

### 1.2. Install the `napari-activelearning` plugin using `pip`

::: {.callout-important}
If you installed `napari` using conda, activate that same environment before installing the _Active Learning_ plugin.
:::

Install the plugin adding `[cellpose]` to the command so all dependencies required for this tutorial are available.

```
python -m pip install "napari-activelearning[cellpose]"
```


# 2. Image groups management

## 2.1. Load a sample image

You can use the cells 3D image sample from napari's built-in samples.

```
File > Open Sample > napari builtins > Cells (3D+2Ch)
```

``` {python}
#| echo: false
import napari
from PIL import Image, ImageDraw, ImageFont
import napari_activelearning as al
import zarr
from scipy.interpolate import splprep, splev
import numpy as np
```

``` {python}
#| echo: false

# Function to generate Bezier curve points
def bezier_curve(points, num_points=100):
    points = np.array(points)
    tck, u = splprep(points.T, s=0)
    u_new = np.linspace(u.min(), u.max(), num_points)
    x_new, y_new = splev(u_new, tck, der=0)
    return list(zip(x_new, y_new))


def draw_text(draw, text, text_pos, text_size=36):
    pos_x, pos_y = text_pos

    font = ImageFont.truetype("arialbd.ttf", size=text_size + 1)
    draw.text((pos_x-1, pos_y-1), "1", fill="black", font=font)
    draw.text((pos_x-1, pos_y+1), "1", fill="black", font=font)
    draw.text((pos_x+1, pos_y+1), "1", fill="black", font=font)
    draw.text((pos_x+1, pos_y-1), "1", fill="black", font=font)
    font = ImageFont.truetype("arial.ttf", size=text_size)
    draw.text((pos_x, pos_y), text, fill="white", font=font)


def draw_annotation(draw, tl, br, item_annotation=None, item_annotation_position="W", item_annotation_fontsize=36):
    tl_x, tl_y = tl
    br_x, br_y = br

    draw.rectangle([tl_x - 5, tl_y - 5, br_x + 5, br_y + 5], outline="white", width=5)
    draw.rectangle([tl_x - 5, tl_y - 5, br_x + 5, br_y + 5], outline="green", width=2)

    if item_annotation is not None:
        if item_annotation_position == "N":
            pos_x, pos_y = (br_x + tl_x) / 2, tl_y - 40
        elif item_annotation_position == "S":
            pos_x, pos_y = (br_x + tl_x) / 2, br_y + 5
        elif item_annotation_position == "E":
            pos_x, pos_y = br_x + 20, (br_y + tl_y) / 2 - 20
        elif item_annotation_position == "NE":
            pos_x, pos_y = br_x - 40, tl_y - 40
        elif item_annotation_position == "NW":
            pos_x, pos_y = tl_x, tl_y - 40
        elif item_annotation_position == "SE":
            pos_x, pos_y = br_x - 40, br_y + 5
        elif item_annotation_position == "SW":
            pos_x, pos_y = tl_x, br_y + 5
        else: # default or item_annotation_position == "W":
            pos_x, pos_y = tl_x - 35, (br_y + tl_y) / 2 - 20

        draw_text(draw, str(item_annotation), (pos_x, pos_y), text_size=item_annotation_fontsize)


def highlight_layers(draw, layer_list, layer_item,
  item_annotation=None,
  item_annotation_position=None,
  item_annotation_fontsize=36,
  offset_x=0,
  offset_y=0):
    main_window = viewer.window._qt_window
    main_window_global = main_window.mapToGlobal(main_window.rect().topLeft())
    if not isinstance(layer_item, tuple):
        layer_item = (layer_item, layer_item)

    rect = layer_list.visualRect(layer_item[0])
    tl = layer_list.viewport().mapToGlobal(rect.topLeft())
    tl_x, tl_y = tl.x() - main_window_global.x() - offset_x, tl.y() - main_window_global.y() - offset_y

    rect = layer_list.visualRect(layer_item[-1])
    br = layer_list.viewport().mapToGlobal(rect.bottomRight())
    br_x, br_y = br.x() - main_window_global.x() - offset_x, br.y() - main_window_global.y() - offset_y

    draw_annotation(draw, (tl_x, tl_y), (br_x, br_y), item_annotation, item_annotation_position, item_annotation_fontsize)


def highlight_widget(draw, layout, item_idx,
  item_annotation=None,
  item_annotation_position=None,
  item_annotation_fontsize=36,
  offset_x=0,
  offset_y=0):
    main_window = viewer.window._qt_window
    main_window_global = main_window.mapToGlobal(main_window.rect().topLeft())

    if not isinstance(item_idx, tuple):
        item_idx = (item_idx, item_idx)

    focus_widget = layout().itemAt(item_idx[0]).widget()
    tl = focus_widget.mapToGlobal(focus_widget.rect().topLeft())
    tl_x, tl_y = tl.x() - main_window_global.x() - offset_x, tl.y() - main_window_global.y() - offset_y

    focus_widget = layout().itemAt(item_idx[-1]).widget()
    br = focus_widget.mapToGlobal(focus_widget.rect().bottomRight())
    br_x, br_y = br.x() - main_window_global.x() - offset_x, br.y() - main_window_global.y() - offset_y

    draw_annotation(draw, (tl_x, tl_y), (br_x, br_y), item_annotation, item_annotation_position, item_annotation_fontsize)


def highlight_item(draw, item, tree_widget, item_annotation=None,
  item_annotation_position=None,
  item_annotation_fontsize=36,
  offset_x=0,
  offset_y=0):
    main_window = viewer.window._qt_window
    main_window_global = main_window.mapToGlobal(main_window.rect().topLeft())

    if not isinstance(item, tuple):
        item = (item, item)

    rect = tree_widget.visualItemRect(item[0])
    tl = tree_widget.viewport().mapToGlobal(rect.topLeft())
    rect = tree_widget.visualItemRect(item[1])
    br = tree_widget.viewport().mapToGlobal(rect.bottomRight())

    tl_x, tl_y = tl.x() - main_window_global.x() - offset_x, tl.y() - main_window_global.y() - offset_y

    br_x, br_y = br.x() - main_window_global.x() - offset_x, br.y() - main_window_global.y() - offset_y

    draw_annotation(draw, (tl_x, tl_y), (br_x, br_y), item_annotation, item_annotation_position, item_annotation_fontsize)


def crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0):
    image = Image.fromarray(screenshot)

    org_height, org_width = screenshot.shape[:2]

    roi = (org_width * width_prop, org_height * height_prop, org_width, org_height)

    # Crop the image
    cropped_image = image.crop(roi)

    draw = ImageDraw.Draw(cropped_image)

    return cropped_image, draw, org_width * width_prop, org_height * height_prop

screenshot_scale = 0.5
```

``` {python}
#| echo: false
viewer = napari.Viewer()
viewer.window._qt_window.showMaximized()
_ = viewer.open_sample(plugin="napari", sample="cells3d")

layer_list = viewer.window.qt_viewer.dockLayerList.widget().layout().itemAt(1).widget()
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)
image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

## 2.2. Add the _Image Groups Manager_ widget to napari's window

The _Image groups manager_ can be found under the _Active Learning_ plugin in napari's plugins menu.

```
Plugins > Active Learning > Image groups manager
```

``` {python}
#| echo: false
image_groups_mgr, acquisition_fun_cfg, label_groups_mgr = al.get_active_learning_widget()
```
``` {python}
#| echo: false
image_groups_mgr_dw = viewer.window.add_dock_widget(image_groups_mgr)
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)

# Select the two image layers
draw = ImageDraw.Draw(image)
draw.rectangle([125, 0, 185, 25], outline="white", width=5)
draw.rectangle([125, 0, 185, 25], outline="green", width=2)

image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

## 2.3. Create an _Image Group_ containing _nuclei_ and _membrane_ layers

1. Select the _nuclei_ and _membrane_ layer.

2. Click the _New Image Group_ button on the _Image Groups Manager_ widget.

``` {python}
#| echo: false
viewer.layers.selection.clear()
viewer.layers.selection.add(viewer.layers["nuclei"])
viewer.layers.selection.add(viewer.layers["membrane"])
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.0, height_prop=0.0)

# Select the Mask layer
layer_items = tuple(layer_list.selectedIndexes())

highlight_layers(draw, layer_list, layer_items, item_annotation=1, item_annotation_position="E", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, image_groups_mgr.layout, 0, item_annotation=2, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
``` {python}
#| echo: false
image_groups_mgr.create_group()
```

## 2.4. Edit the image group properties

:::: {.columns}

::: {.column width=0.3}
1. Select the "images" _channel group_ that has been created under the new image group.

::: {.callout-note title="Note on image groups hierarchy" collapse="true"}
The hierarchical structure of groups within this plugin is the following:

* *Image groups*. Used to contain different modes of data, such as images, labels, masks, segmentation labels, etc.

    + *Layers groups*. These group multiple layers together, and are intended to contain data from the same mode such different channel layers of the same image.

        - *Layer channels*. This is directly related to a napari layer from the _layer list_ widget, but allows to store additional information that is useful for the inference or fine-tuning process, such as the name and order of the axes.
:::

2. Click the _Edit group properties_ checkbox.

3. Make sure that _Axes order_ is "CZYX", otherwise, you can edit it and press _Enter_ to update the axes names.
:::

::: {.column width=0.7}
``` {python}
#| echo: false
focus_widget = image_groups_mgr.image_groups_editor.layout().itemAt(0).widget()
focus_widget.setChecked(True)

image_groups_mgr._active_image_group.child(0).setSelected(True)
image_groups_mgr.image_groups_editor.edit_axes_le.setText("CZYX")
image_groups_mgr.image_groups_editor.update_source_axes()
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_item(draw, image_groups_mgr.groups_root.child(0).child(0), image_groups_mgr.image_groups_tw, item_annotation=1, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, image_groups_mgr.image_groups_editor.layout, 0, item_annotation=2, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, image_groups_mgr.image_groups_editor.editor_widget.layout, (8, 9), item_annotation=3, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
:::

::::

# 3. Segmentation on image groups

## 3.1. Add the _Acquisition function configuration_ widget to napari's window

The _Acquisition function configuration_ is under the _Active Learning_ plugin in napari's plugins menu.

```
Plugins > Active Learning > Acquisition function configuration
```

::: {.callout-tip}
All _Active Learning_ widgets can be _un-docked_ from their current place and _re-docked_ into other more convenient location within napari's window, or even as tabs, as illustrated in this tutorial.
:::

``` {python}
#| echo: false
acquisition_fun_cfg_dw = viewer.window.add_dock_widget(acquisition_fun_cfg)
viewer.window._qt_window.tabifyDockWidget(image_groups_mgr_dw, acquisition_fun_cfg_dw)

image_groups_mgr_dw.setWindowTitle("Image groups manager")
acquisition_fun_cfg_dw.setWindowTitle("Acquisition function configuration")
```
``` {python}
#| echo: false
acquisition_fun_cfg_dw.raise_()
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)
image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

## 3.2. Define sampling configuration

:::: {.columns}

::: {.column width=0.7}

1. Make sure "Input axes" are set to "ZYX".

::: {.callout-note title="Note on Input axes" collapse="true"}
This enables edition of the patch size at those selected **spatial** axes.

For example, the "Cells (3D+2Ch)" sample image is three-dimensional, with  "ZYX" spatial axes, and has two color channels. For that image we will extract two-dimensional patches of size $256\times256$ pixels, in the "X" and "Y" spatial axes.

Therefore, "Input axes"="ZYX" allows to set the patch size at spatial axes "Y" and "X" to $256$ pixels, and "Z" to $1$ in order to extract one-slice-deep patches.
:::

2. Change the "Model axes" to "CYX".

::: {.callout-note title="Note on Model axes" collapse="true"}
This, on the other hand, specifies the order our model expects to receive its inputs.

In his case, the nuclei model from `cellpose` will be applied to two-dimensional images. Because the "Z" axis is not used, we drop it from the "Model axes" string. This is only possible because the "Z" axis is already set to $1$ slice deep and can be _squeezed_ from the patch.

Additionally, we append the "C" (color channel) axis to the beginning of the string. That means that the order of the patch axes will be permuted to have the color channel as leading axis.
:::

:::

::: {.column width=0.3}

``` {python}
#| echo: false
acquisition_fun_cfg.input_axes_le.setText("ZYX")
acquisition_fun_cfg._set_input_axes()
acquisition_fun_cfg.model_axes_le.setText("CYX")
acquisition_fun_cfg._set_model_axes()
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, acquisition_fun_cfg.layout, (6, 7), item_annotation=1, item_annotation_position="N", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.layout, (8, 9), item_annotation=2, item_annotation_position="N", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
:::

::::

## 3.3. Set the size of the sampling patch

:::: {.columns}

::: {.column width=0.3}

``` {python}
#| echo: false
focus_widget = acquisition_fun_cfg.layout().itemAt(0).widget()
focus_widget.setChecked(True)

acquisition_fun_cfg.patch_sizes_mspn.sizes = {"Z": 1, "Y": 256, "X": 256}
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, acquisition_fun_cfg.layout, 0, item_annotation=1, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.layout, 1, item_annotation=2, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

:::

::: {.column width=0.7}

1. Click the "Edit patch size" checkbox
2. Change the patch size of "X" and "Y" to 256, and the "Z" axis to 1.

:::{.callout-note}
This directs the Active Learning plugin to sample at random patches of size $256\times256$ pixels and $1$ slice deep.
:::

:::

::::

## 3.4. Define the maximum number of samples to extract {#sec-max-samples}

:::: {.columns}

::: {.column width=0.3}

``` {python}
#| echo: false
acquisition_fun_cfg.max_samples_spn.setValue(4)
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, acquisition_fun_cfg.layout, (2, 3), item_annotation=None, item_annotation_position="N", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

:::

::: {.column width=0.7}
- Set the "Maximum samples" to $4$ and press _Enter_

:::{.callout-note}
This tells the Active Learning plugin to process at most _four_ samples at random from the whole image.

Because the image is of size $256\times256$ pixels, four whole slices will be sampled at random for segmentation.
:::

:::

::::


## 3.5. Configure the segmentation method

:::: {.columns}

::: {.column width=0.7}

1. Use the "Model" dropdown list to select the `cellpose` method

2. Click the "Advanced segmentation parameters" checkbox

3. Change the "Channel axis" to $0$

::: {.callout-note}
This makes `cellpose` to use the first axis as "Color" channel, as we already set in "Model axes"="CYX".
:::

4. Change the second channel to $1$ (the right spin box in the "channels" row)

::: {.callout-note}
This tells `cellpose` to segment the first channel ($0$) and use the second channel ($1$) as help channel.
:::

5. Choose the "nuclei" model from the dropdown list


:::

::: {.column width=0.3}
``` {python}
#| echo: false
acquisition_fun_cfg.methods_cmb.setCurrentIndex(2)
acquisition_fun_cfg.tunable_segmentation_method.advanced_segmentation_options_chk.setChecked(True)
acquisition_fun_cfg.tunable_segmentation_method._segmentation_parameters.channel_axis.value = 0
acquisition_fun_cfg.tunable_segmentation_method._segmentation_parameters.channels.value = (0, 1)
acquisition_fun_cfg.tunable_segmentation_method._segmentation_parameters.model_type.value = "nuclei"
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, acquisition_fun_cfg.layout, (10, 11), item_annotation=1, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method.layout, 0, item_annotation=2, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method._segmentation_parameters.native.layout, 0, item_annotation=3, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method._segmentation_parameters.native.layout, 1, item_annotation=4, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method._segmentation_parameters.native.layout, 3, item_annotation=5, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

:::

::::

## 3.6. Execute the segmentation method on all image groups

:::: {.columns}

::: {.column width=0.6}
- Click the "Run on all image groups" button

::: {.callout-note}
To execute the segmentation only on specific image groups, select the desired image groups in the _Image groups manager_ widget and use the "Run on selected image groups" button instead.
:::

:::

::: {.column width=0.4}
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, acquisition_fun_cfg.layout, 13, item_annotation=None, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
``` {python}
#| echo: false
_ = acquisition_fun_cfg.compute_acquisition_layers(run_all=True)
```
:::

::::

## 3.7. Inspect the segmentation layer

- We will only see four segmented slices from the whole image. This is because we set the "Maximum samples" parameter to $4$ in @sec-max-samples.

::: {.callout-note}
Because the input image is 3D, you may have to slide the "Z" index at the bottom of napari's window to look at the samples that were segmented.
:::

``` {python}
#| echo: false
label_groups_mgr.focus_region(
  label_groups_mgr.labels_group_root.child(0).child(0)
)
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)
image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

# 4. Segment masked regions only {#sec-mask}

## 4.1. Create a mask to restrict the sampling space

:::: {.columns}

::: {.column width=0.6}
1. Switch to the _Image groups manager_ tab

2. Click the "Edit mask properties" checkbox

3. Set the mask scale to $256$ for the "X" and "Y" axes, and a scale of $1$ for the "Z" axis

4. Click the "Create mask" button

::: {.callout-note}
This creates a low-resolution mask where each of its pixels corresponds to a $256\times256$ pixels region in the input image.
Because the mask is low-resolution, it uses less space in memory and disk.
:::

:::

::: {.column width=0.4}
``` {python}
#| echo: false
image_groups_mgr_dw.raise_()

focus_widget = image_groups_mgr.mask_generator.layout().itemAt(0).widget()
focus_widget.setChecked(True)

image_groups_mgr.mask_generator.patch_sizes_mspn.sizes = {"Z": 1, "Y": 256, "X": 256}
image_groups_mgr.mask_generator.generate_mask_layer()
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, image_groups_mgr.mask_generator.layout, 0, item_annotation=2, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, image_groups_mgr.mask_generator.edit_mask_widget.layout, 0, item_annotation=3, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, image_groups_mgr.mask_generator.edit_mask_widget.layout, 1, item_annotation=4, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

:::

::::

## 4.2. Specify the samplable regions

:::: {.columns}

::: {.column width=0.6}

1. Make sure the newly created layer "images mask" is selected.

2. Activate the paint brush tool (or press 2 or P keys in the keyboard as shortcuts).

3. Move the "brush size" slider to set a size of $1$ pixel in the mask scale. Because we set a scale of $256$ on "X" and "Y" axis, this translates to a region of $256\times256$ pixels on the original image. 

4. Click and drag on the image to draw the mask on the current slice.

5. Move the slider at the bottom of napari's window to navigate between slices in the "Z" axis. Select slide $28$ and draw on it as in step $4$. Repeat with slices $29$ and $30$.

:::

::: {.column width=0.4}

``` {python}
#| echo: false
viewer.camera.center = (27, 128, 128)
viewer.dims.current_step = (27, 128, 128)
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)
image = Image.fromarray(screenshot)

offset_x, offset_y = 0, 0

roi = (offset_x, offset_y, org_width * 0.7, org_height)

# Crop the image
cropped_image = image.crop(roi)

draw = ImageDraw.Draw(cropped_image)

# Select the Mask layer
viewer.layers.selection.clear()
layer = viewer.layers["images mask"]
viewer.layers.selection.add(layer)

layer_items = layer_list.selectedIndexes()

highlight_layers(draw, layer_list, layer_items[0], item_annotation=1, item_annotation_position="E", item_annotation_fontsize=25, offset_x=offset_x, offset_y=offset_y)

# Select the paint brush
draw_text(draw, "2", (85, 15), text_size=36)

draw.rectangle([80, 50, 120, 90], outline="white", width=5)
draw.rectangle([80, 50, 120, 90], outline="green", width=2)

# Resize brush
draw_text(draw, "3", (300, 170), text_size=36)

draw.rectangle([5, 170, 280, 200], outline="white", width=5)
draw.rectangle([5, 170, 280, 200], outline="green", width=2)

# Draw mask
draw_text(draw, "4", (500, 110), text_size=50)
draw.circle((500, 200), 150, fill=None, outline='white', width=3)
draw.circle((1100, 800), 150, fill=None, outline='white', width=3)

control_points = [(500, 200), (850, 400), (750, 600), (1100, 800)]

curve_points = bezier_curve(control_points, num_points=100)

# Draw the Bezier curve
draw.line(curve_points, fill='green', width=50)
draw.line(curve_points, fill='white', width=30)

# Slide Z axis
draw_text(draw, "5", (745, 960), text_size=36)

draw.rectangle([295, 1000, 1280, 1035], outline="white", width=5)
draw.rectangle([295, 1000, 1280, 1035], outline="green", width=2)

cropped_image.resize((int(screenshot_scale * 0.7 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
``` {python}
#| echo: false
viewer.camera.center = (27, 128, 128)
viewer.dims.current_step = (27, 128, 128)

viewer.layers["images mask"].data[0, 0, 27:31, 0, 0] = 1
viewer.layers["images mask"].refresh()
```

:::

::::

## 4.3. Execute the segmentation process on the masked regions and inspect  the results

- Run again the segmentation process (clicking "Run on all image groups" button).

::: {.callout-important}
All slices between $27$ and $30$ were picked and segmented thanks to the sampling mask!
:::

``` {python}
#| echo: false
_ = acquisition_fun_cfg.compute_acquisition_layers(run_all=True)
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)
image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

# 5. Fine tune the segmentation model

## 5.1. Add the _Label groups manager_ widget to napari's window

You can find the _Label groups manager_ under the _Active Learning_ plugin in napari's plugins menu.

```
Plugins > Active Learning > Label groups manager
```

``` {python}
#| echo: false
label_groups_mgr_dw = viewer.window.add_dock_widget(label_groups_mgr)
viewer.window._qt_window.tabifyDockWidget(acquisition_fun_cfg_dw, label_groups_mgr_dw)

label_groups_mgr_dw.setWindowTitle("Label groups manager")
```
``` {python}
#| echo: false
label_groups_mgr_dw.raise_()
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)
image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```


## 5.2. Select a segmented patch to edit

- Double click on any of the segmented patches in the viewer 
(e.g. any slice between $27$ and $30$)

::: {.callout-note}
This creates a new editable "Labels edit" layer with a copy of the selected patch.
:::

``` {python}
#| echo: false
label_groups_mgr.labels_table_tw.setCurrentItem(label_groups_mgr.labels_group_root.child(1).child(3), 0)
label_groups_mgr.focus_region(
  label_groups_mgr.labels_group_root.child(1).child(3),
  edit_focused_label=True
)
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)
image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

## 5.3. Use napari's layer controls to make changes on the objects of the current patch

::: {.callout-tip}
You can follow [this tutorial](https://napari.org/dev/howtos/layers/labels.html#creating-deleting-merging-and-splitting-connected-components) to learn how to use the annotation tools in napari.
:::

``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

image = Image.fromarray(screenshot)
image


draw = ImageDraw.Draw(image)

# Draw a red rectangle
draw.rectangle([5, 20, 280, 385], outline="white", width=5)
draw.rectangle([5, 20, 280, 385], outline="green", width=2)

image
```

## 5.4. Commit changes to the labels layer

- Once you have finished editing the labels, click the "Commit changes" button on the _Label groups manager_

``` {python}
#| echo: false
z_tmp = zarr.open(r"C:\Users\Public\Documents\membrane.zarr\segmentation\0", mode="r")

label_groups_mgr.labels_group_root.child(1).child(3)._position
viewer.layers["Labels edit"].data[:] = z_tmp[label_groups_mgr.labels_group_root.child(1).child(3)._position]
viewer.layers["Labels edit"].refresh()
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.0, height_prop=0.0)

highlight_widget(draw, label_groups_mgr.layout, 6, item_annotation=None, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
``` {python}
#| echo: false
label_groups_mgr.commit()
```

## 5.5. Navigate between segmented patches

:::: {.columns}

::: {.column width=0.6}
1. Expand the second group of labels

2. Double-click on any of the nested items to open it for editing

3. Use the navigation buttons to move between segmented patches

4. Continue editing the segmentation in the current patch and commit the changes when finished

5. Repeat this with each of the segmented patches.

::: {.callout-note}
Every time we run the segmentation process, a new _group_ of labels is added to the _Label groups manager_.
:::

:::

::: {.column width=0.4}

``` {python}
#| echo: false
label_groups_mgr.labels_table_tw.expandItem(label_groups_mgr.labels_group_root.child(1))
label_groups_mgr.labels_table_tw.setCurrentItem(label_groups_mgr.labels_group_root.child(1).child(0), 0)
label_groups_mgr.focus_region(
  label_groups_mgr.labels_group_root.child(1).child(0),
  edit_focused_label=True
)
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

image = Image.fromarray(screenshot)

offset_x, offset_y = (org_width * 0.7, 0)

roi = (offset_x, offset_y, org_width, org_height)

# Crop the image
cropped_image = image.crop(roi)

draw = ImageDraw.Draw(cropped_image)

# Draw a red rectangle
highlight_item(draw, label_groups_mgr.labels_group_root.child(1), label_groups_mgr.labels_table_tw, item_annotation=1, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_item(draw, (label_groups_mgr.labels_group_root.child(1).child(0), label_groups_mgr.labels_group_root.child(1).child(3)), label_groups_mgr.labels_table_tw, item_annotation=2, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, label_groups_mgr.layout, (1, 4), item_annotation=3, item_annotation_position="N", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, label_groups_mgr.layout, 6, item_annotation=4, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
``` {python}
#| echo: false
for c_idx in range(label_groups_mgr.labels_group_root.child(1).childCount()):
    label_groups_mgr.focus_region(
        label_groups_mgr.labels_group_root.child(1).child(c_idx),
        edit_focused_label=True
    )

    label_groups_mgr.labels_group_root.child(1).child(c_idx)._position
    viewer.layers["Labels edit"].data[:] = z_tmp[label_groups_mgr.labels_group_root.child(1).child(c_idx)._position]
    label_groups_mgr.commit()

```

:::

::::

## 5.6. Setup fine tuning configuration

:::: {.columns}

::: {.column width=0.6}

1. Go to the _Acquisition function configuration_ widget

2. Click the "Advanced fine tuning parameters" checkbox

3. Change the "save path" to a location where you want to store the fine tuned model

:::

::: {.column width=0.4}

``` {python}
#| echo: false
acquisition_fun_cfg_dw.raise_()
```
``` {python}
#| echo: false
acquisition_fun_cfg.tunable_segmentation_method.advanced_finetuning_options_chk.setChecked(True)
acquisition_fun_cfg.tunable_segmentation_method._finetuning_parameters.save_path.value = "C:/Users/Public/Documents/models"
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method.layout, 1, item_annotation=2, item_annotation_position="E", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method._finetuning_parameters.native.layout, 6, item_annotation=3, item_annotation_position="NE", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)
cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

:::

::::

## 5.6. Setup fine tuning configuration

:::: {.columns}

::: {.column width=0.6}

4. Change the "model name" to "nuclei_ft"

::: {.callout-tip}
Scroll the _Advanced fine tuning parameters_ widget down to show more parameters.
:::

5. Set the "batch size" to $3$

6. Change the "learning rate" to $0.0001$

::: {.callout-tip}
You can modify other parameters for the training process here, such as the number of training epochs.
:::

:::

::: {.column width=0.4}

``` {python}
#| echo: false
vertical_scroll_bar = acquisition_fun_cfg.tunable_segmentation_method._finetuning_parameters_scr.verticalScrollBar()
vertical_scroll_bar.setValue(vertical_scroll_bar.maximum())
 
acquisition_fun_cfg.tunable_segmentation_method._finetuning_parameters.model_name.value = "nuclei_ft"
acquisition_fun_cfg.tunable_segmentation_method._finetuning_parameters.batch_size.value = 3
acquisition_fun_cfg.tunable_segmentation_method._finetuning_parameters.learning_rate.value = 0.0001
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method._finetuning_parameters.native.layout, 14, item_annotation=4, item_annotation_position="W", item_annotation_fontsize=30, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method._finetuning_parameters.native.layout, 15, item_annotation=5, item_annotation_position="W", item_annotation_fontsize=30, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method._finetuning_parameters.native.layout, 16, item_annotation=6, item_annotation_position="W", item_annotation_fontsize=30, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

:::

::::

## 5.7. Execute the fine tuning process

:::: {.columns}

::: {.column width=0.6}
- Click the "Fine tune model" button to run the training process.

::: {.callout-caution}
Depending on your computer resources (RAM, CPU), this process might take some minutes to complete. If you have a dedicated GPU device, this can take a couple of seconds instead.
:::

:::

::: {.column width=0.4}

``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, acquisition_fun_cfg.layout, 14, item_annotation=None, item_annotation_position="W", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
``` {python}
#| echo: false
_ = acquisition_fun_cfg.fine_tune()
```

:::

::::

## 5.8. Review the fine tuned segmentation

::: {.callout-tip}
Use the *opacity* slider to compare how the fine tuned model segments the same objects that were labeled for training.
:::

``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)

draw = ImageDraw.Draw(image)

# Draw a red rectangle
draw.rectangle([10, 90, 280, 120], outline="white", width=5)
draw.rectangle([10, 90, 280, 120], outline="green", width=2)

image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

# 6. Use the fine tuned model for inference

## 6.1. Create a mask to apply the fine tuned model for inference

:::: {.columns}

::: {.column width=0.6}

1. Follow the steps from @sec-mask to create a mask, now covering slices $31$ to $34$.

2. Scroll down the _Image groups manager_ tree to show the newest mask layer grup ("mask (1)").

3. Select the "mask (1)" layer group

::: {.callout-tip}
The "Group name" column in the groups tree can be resized to show the complete names.
:::

4. Make sure that "Use as sampling mask" checkbox is checked.


5. Click "Run on all image groups" button in the _Acquisition function configuration_ widget again.
:::

::: {.column width=0.4}

``` {python}
#| echo: false
image_groups_mgr_dw.raise_()

focus_widget = image_groups_mgr.mask_generator.layout().itemAt(0).widget()
focus_widget.setChecked(True)

image_groups_mgr.mask_generator.patch_sizes_mspn.sizes = {"Z": 1, "Y": 256, "X": 256}
image_groups_mgr.mask_generator.generate_mask_layer()

viewer.camera.center = (31, 128, 128)
viewer.dims.current_step = (31, 128, 128)

viewer.layers["images mask (1)"].data[0, 0, 31:35, 0, 0] = 1
viewer.layers["images mask (1)"].refresh()

image_groups_mgr.image_groups_tw.clearSelection()

vertical_scroll_bar = image_groups_mgr.image_groups_tw.verticalScrollBar()
vertical_scroll_bar.setValue(vertical_scroll_bar.maximum())

image_groups_mgr.groups_root.child(0).child(image_groups_mgr.groups_root.child(0).childCount() - 1).setSelected(True)
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_item(draw, image_groups_mgr.groups_root.child(0).child(image_groups_mgr.groups_root.child(0).childCount() - 1), image_groups_mgr.image_groups_tw, item_annotation=3, item_annotation_position="N", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, image_groups_mgr.image_groups_editor.editor_widget.layout, 15, item_annotation=4, item_annotation_position="E", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

:::

::::

## 6.2. Inspect the output of the fine tuned model

- Now you have a fine tuned model for nuclei segmentation that has been adapted to this image!

::: {.callout-important}
The fine tuned model can be used in *Cellpose*'s GUI software, their python API package, or any other package that supports pretrained `cellpose` models.
:::

``` {python}
#| echo: false
_ = acquisition_fun_cfg.compute_acquisition_layers(run_all=True)

viewer.camera.center = (33, 128, 128)
viewer.dims.current_step = (33, 128, 128)
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
image = Image.fromarray(screenshot)
image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```

## 6.3. Segment the newly masked region with the base model for comaprison

:::: {.columns}

::: {.column width=0.6}

1. Choose the "nuclei" model again from the dropdown list in the _Advanced segmentation parameters_ section

2. Click the "Run on all image groups" button again

::: {.callout-note}
This will execute the segmentation process with the non-fine-tuned "nuclei" model on the same sampling positions from the last run.
:::

:::

::: {.column width=0.4}

``` {python}
#| echo: false
acquisition_fun_cfg_dw.raise_()
 
vertical_scroll_bar = acquisition_fun_cfg.tunable_segmentation_method._segmentation_parameters_scr.verticalScrollBar()
vertical_scroll_bar.setValue(vertical_scroll_bar.maximum())

acquisition_fun_cfg.tunable_segmentation_method._segmentation_parameters.model_type.value = "nuclei"
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]

cropped_image, draw, offset_x, offset_y = crop_screenshot(screenshot, width_prop=0.7, height_prop=0.0)

highlight_widget(draw, acquisition_fun_cfg.tunable_segmentation_method._segmentation_parameters.native.layout, 3, item_annotation=1, item_annotation_position="S", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

highlight_widget(draw, acquisition_fun_cfg.layout, 13, item_annotation=2, item_annotation_position="E", item_annotation_fontsize=36, offset_x=offset_x, offset_y=offset_y)

cropped_image.resize((int(screenshot_scale * 0.3 * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
``` {python}
#| echo: false
_ = acquisition_fun_cfg.compute_acquisition_layers(run_all=True)
```
:::

::::

## 6.4. Compare the results of both models

- Hide all the layers except the "nuclei" and "membrane" layers, and the "images segmentation [2]" and "images segmentation [3]" layers, that are the segmentation outputs from the fine-tuned model and base model, respectively.

::: {.callout-tip}
Click the **eye** icon in the "layer list" to hide/show layers.
:::


``` {python}
#| echo: false
for layer in viewer.layers:
    layer.visible = layer.name in ("images segmentation [2]", "images segmentation [3]", "nuclei", "membrane")
```
``` {python}
#| echo: false
screenshot = viewer.screenshot(canvas_only=False, flash=False)
org_height, org_width = screenshot.shape[:2]
offset_x, offset_y = 0, 0
image = Image.fromarray(screenshot)

draw = ImageDraw.Draw(image)

viewer.layers.selection.clear()
layer = viewer.layers["images segmentation [3]"]
viewer.layers.selection.add(layer)

# Draw a red rectangle
layer_items = layer_list.selectedIndexes()

highlight_layers(draw, layer_list, layer_items[0], item_annotation="< base model", item_annotation_position="E", item_annotation_fontsize=25, offset_x=offset_x, offset_y=offset_y)

viewer.layers.selection.clear()
layer = viewer.layers["images segmentation [2]"]
viewer.layers.selection.add(layer)

layer_items = layer_list.selectedIndexes()

highlight_layers(draw, layer_list, layer_items[0], item_annotation="< fine-tuned model", item_annotation_position="E", item_annotation_fontsize=25, offset_x=offset_x, offset_y=offset_y)

image.resize((int(screenshot_scale * org_width), int(screenshot_scale * org_height)), Image.Resampling.LANCZOS)
```
